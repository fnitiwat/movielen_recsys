{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBasic\n",
    "from surprise import NormalPredictor\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pandas_profiling import ProfileReport\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    links_csv_path = \"../data/movielens-small/links.csv\"\n",
    "    movies_csv_path = \"../data/movielens-small/movies.csv\"\n",
    "    ratings_csv_path = \"../data/movielens-small/ratings.csv\"\n",
    "    tags_csv_path = \"../data/movielens-small/tags.csv\"\n",
    "    artifact_dir = \"./artifacts/\"\n",
    "\n",
    "\n",
    "config = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df = pd.read_csv(config.links_csv_path)\n",
    "movies_df = pd.read_csv(config.movies_csv_path)\n",
    "ratings_df = pd.read_csv(config.ratings_csv_path)\n",
    "tags_df = pd.read_csv(config.tags_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies_df), len(movies_df.groupby(\"title\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run pandas profile to see stat of data\n",
    "\n",
    "# for curr_df in [links_df, movies_df, ratings_df, tags_df]:\n",
    "#     profile = ProfileReport(curr_df, title=\"Pandas Profiling Report\")\n",
    "#     profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie: Title is duplicate\n",
    "\n",
    "# get movie that have duplicate title\n",
    "duplicate_title_movie_df = movies_df[\n",
    "    movies_df.title.isin(movies_df[movies_df.duplicated(\"title\")].title.tolist())\n",
    "]\n",
    "display(duplicate_title_movie_df)\n",
    "\n",
    "# remove duplicate row\n",
    "movies_df = movies_df[~movies_df.duplicated(\"title\")]\n",
    "\n",
    "\n",
    "# TODO: instead just remove -> merge genres (if u want to use genres to do something)\n",
    "# TODO: convert movieID of another relate\n",
    "# TODO: create map movieId\n",
    "def get_duplicate_movie_id_mapping() -> Dict[str, str]:\n",
    "    \"\"\"get dictionary that map movie_id that have duplicate title to another id that is we want to use\n",
    "    Returns:\n",
    "        Dict[str, str]: dictionary that map input_movie_id to target_movie_id\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = duplicate_title_movie_df.groupby(\"title\")\n",
    "\n",
    "for key, item in grouped_df:\n",
    "    display(grouped_df.get_group(key))\n",
    "    x = grouped_df.get_group(key).movieId.tolist()\n",
    "    print(x)\n",
    "\n",
    "    ratings_df[ratings_df.movieId.isin(x)]\n",
    "\n",
    "    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(ratings_df), len(ratings_df.groupby([\"userId\", \"movieId\"]))\n",
    "# x = ratings_df.groupby([\"userId\", \"movieId\"])\n",
    "# z = x.count()\n",
    "# z[z.rating == 1]\n",
    "# x.count().iloc[2]\n",
    "# ratings_df\n",
    "# grouped_df.get_group(ratings_df[ratings_df.movieId.isin(duplicate_title_movie_df.movieId)].groupby(\"userId\").count()\n",
    "# duplicate_titles = []\n",
    "\n",
    "# # merge row\n",
    "# # - use_first_movie_id\n",
    "# # - keep duplicate_title_movie_df\n",
    "# # - concat genres\n",
    "# # - get map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Links: Find missing in tmdlbld (but not do anything)\n",
    "\n",
    "not_in_tmdbld_movie_ids = links_df[links_df.tmdbId.isna()].movieId.tolist()\n",
    "# show row that tmfbId is nan\n",
    "display(movies_df[movies_df.movieId.isin(not_in_tmdbld_movie_ids)])\n",
    "\n",
    "# i think this happen because movie have in imdbld but not in tmdbld\n",
    "# should not have effect much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings: Remove row rating outside rang[0,5] and remove row userId missing\n",
    "\n",
    "# show row where rating value outside range\n",
    "print(\"row where rating outside range:\")\n",
    "display(ratings_df[((ratings_df.rating > 5) | (ratings_df.rating < 0))])\n",
    "\n",
    "# show row where user is nan\n",
    "print(\"row where user is nan:\")\n",
    "display(ratings_df[ratings_df.userId.isna()])\n",
    "\n",
    "# remove row where rating is outside [0,5]\n",
    "ratings_df = ratings_df[~((ratings_df.rating > 5) | (ratings_df.rating < 0))]\n",
    "\n",
    "# remove row where user is nan\n",
    "ratings_df = ratings_df[~ratings_df.userId.isna()]\n",
    "\n",
    "# check after remove row that have rating out side range [0, 5]\n",
    "print(\"unique rating value:\")\n",
    "print(np.unique(ratings_df.rating, return_counts=True))\n",
    "\n",
    "# check to confirm not have nan user\n",
    "print(\"check is nan in df:\")\n",
    "display(ratings_df[ratings_df.userId.isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "ratings_df = ratings_df.reset_index(drop=True)\n",
    "display(ratings_df)\n",
    "\n",
    "# set movieId as index\n",
    "movies_df = movies_df.set_index(\"movieId\")\n",
    "display(movies_df)\n",
    "\n",
    "# change column name\n",
    "movies_df.columns = movies_df.columns.str.replace(\"title\", \"movie_name\")\n",
    "movies_df.columns = movies_df.columns.str.replace(\"genres\", \"genre\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data\n",
    "\n",
    "cleaned_movies_csv_path = os.path.join(config.artifact_dir, \"cleaned_movies.csv\")\n",
    "cleaned_rating_csv_path = os.path.join(config.artifact_dir, \"cleaned_ratings.csv\")\n",
    "cleaned_links_csv_path = os.path.join(config.artifact_dir, \"cleaned_links.csv\")\n",
    "cleaned_tags_csv_path = os.path.join(config.artifact_dir, \"cleaned_tags.csv\")\n",
    "\n",
    "movies_df.to_csv(cleaned_movies_csv_path)\n",
    "ratings_df.to_csv(cleaned_rating_csv_path)\n",
    "links_df.to_csv(cleaned_links_csv_path)\n",
    "tags_df.to_csv(cleaned_tags_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, ratings_df, config: Config):\n",
    "        self.config = config\n",
    "        self.ratings_df = ratings_df\n",
    "\n",
    "    def run(self):\n",
    "        trainset, testset, train_loocv, test_loocv = self._init_data(\n",
    "            ratings_df=self.ratings_df\n",
    "        )\n",
    "        algorithm_instance = self._init_model()\n",
    "        algorithm_instance = self._train(algorithm_instance, trainset)\n",
    "        eval_report, predictions = self._evaluate(algorithm_instance, testset)\n",
    "        self._save_artifacts(\n",
    "            algorithm_instance,\n",
    "            predictions=predictions,\n",
    "            artifact_dir=config.artifact_dir,\n",
    "        )\n",
    "\n",
    "        self._get_hitrate_results(train_loocv, test_loocv)\n",
    "\n",
    "    def _init_data(self, ratings_df: pd.DataFrame):\n",
    "        reader = Reader(rating_scale=(1, 5))\n",
    "        data = Dataset.load_from_df(\n",
    "            self.ratings_df[[\"userId\", \"movieId\", \"rating\"]], reader\n",
    "        )\n",
    "\n",
    "        # split train, test for eval RMSE\n",
    "        trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "        # split train, test leave one out for eval hit rate\n",
    "        splitter = LeaveOneOut(n_splits=1, random_state=1)\n",
    "        train_loocv, test_loocv = list(splitter.split(data))[0]\n",
    "\n",
    "        return trainset, testset, train_loocv, test_loocv\n",
    "\n",
    "    def _init_model(self) -> surprise.prediction_algorithms.algo_base.AlgoBase:\n",
    "        algorithm_instance = SVD()\n",
    "        return algorithm_instance\n",
    "\n",
    "    def _train(\n",
    "        self,\n",
    "        algorithm_instance: surprise.prediction_algorithms.algo_base.AlgoBase,\n",
    "        trainset,\n",
    "    ):\n",
    "        algorithm_instance.fit(trainset)\n",
    "        return algorithm_instance\n",
    "\n",
    "    def _evaluate(\n",
    "        self,\n",
    "        algorithm_instance: surprise.prediction_algorithms.algo_base.AlgoBase,\n",
    "        testset: any,\n",
    "    ) -> any:\n",
    "        predictions = [\n",
    "            algorithm_instance.predict(uid, iid, r_ui_trans, verbose=False)\n",
    "            for (uid, iid, r_ui_trans) in tqdm(testset, desc=\"making predictions\")\n",
    "        ]\n",
    "        eval_report = accuracy.rmse(predictions)\n",
    "        return eval_report, predictions\n",
    "\n",
    "    def _save_artifacts(\n",
    "        self, algorithm_instance, predictions, artifact_dir: str\n",
    "    ) -> None:\n",
    "        algorithm_instance_save_path = os.path.join(\n",
    "            artifact_dir, \"algorithm_instance.pickle\"\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(algorithm_instance_save_path), exist_ok=True)\n",
    "        surprise.dump.dump(\n",
    "            algorithm_instance_save_path,\n",
    "            algo=algorithm_instance,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "\n",
    "    def _get_hitrate_results(self, train_loocv, test_loocv):\n",
    "        def _get_top_N(predictions, n=10, minimumRating=4.0):\n",
    "            topN = defaultdict(list)\n",
    "\n",
    "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "                if estimatedRating >= minimumRating:\n",
    "                    topN[userID].append((movieID, estimatedRating))\n",
    "\n",
    "            for userID, ratings in topN.items():\n",
    "                ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "                topN[userID] = ratings[:n]\n",
    "\n",
    "            return topN\n",
    "\n",
    "        def _HitRate(topNPredicted, leftOutPredictions):\n",
    "            hits = 0\n",
    "            total = 0\n",
    "\n",
    "            # For each left-out rating\n",
    "            for leftOut in leftOutPredictions:\n",
    "                userID = leftOut[0]\n",
    "                leftOutMovieID = leftOut[1]\n",
    "                # Is it in the predicted top 10 for this user?\n",
    "                hit = False\n",
    "                for movieID, predictedRating in topNPredicted[userID]:\n",
    "                    if leftOutMovieID == movieID:\n",
    "                        hit = True\n",
    "                        break\n",
    "                if hit:\n",
    "                    hits += 1\n",
    "\n",
    "                total += 1\n",
    "\n",
    "            # Compute overall precision\n",
    "            return hits / total\n",
    "\n",
    "        algorithm_instance = self._init_model()\n",
    "        algorithm_instance.fit(train_loocv)\n",
    "        left_out_predictions = algorithm_instance.test(test_loocv)\n",
    "        loocv_anti_testset = train_loocv.build_anti_testset()\n",
    "        all_predictions = algorithm_instance.test(loocv_anti_testset)\n",
    "        top_n_predicted = _get_top_N(all_predictions)\n",
    "        hitrate = _HitRate(top_n_predicted, left_out_predictions)\n",
    "        print(f\"HitRate: {hitrate}\")\n",
    "        return all_predictions\n",
    "\n",
    "\n",
    "trainer = Trainer(ratings_df=ratings_df, config=config)\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DB:\n",
    "    def __init__(\n",
    "        self,\n",
    "        links_csv_path: str,\n",
    "        movies_csv_path: str,\n",
    "        ratings_csv_path: str,\n",
    "        tags_csv_path: str,\n",
    "    ):\n",
    "        self.links_df = pd.read_csv(links_csv_path)\n",
    "        self.movies_df = pd.read_csv(movies_csv_path).set_index(\"movieId\")\n",
    "        self.ratings_df = pd.read_csv(ratings_csv_path)\n",
    "        self.tags_df = pd.read_csv(tags_csv_path)\n",
    "\n",
    "    def get_metadata_from_movie_id(self, movie_id: int) -> Dict:\n",
    "        selected_row = self.movies_df.loc[movie_id]\n",
    "        metadata = {\n",
    "            \"id\": str(movie_id),\n",
    "            \"title\": selected_row.movie_name,\n",
    "            \"genres\": selected_row.genre.split(\"|\"),\n",
    "        }\n",
    "        return metadata\n",
    "\n",
    "    def get_watched_movie_ids_from_user_id(self, user_id: int) -> List[int]:\n",
    "        watched_movie_ids = self.ratings_df[\n",
    "            self.ratings_df.userId == user_id\n",
    "        ].movieId.tolist()\n",
    "        return watched_movie_ids\n",
    "\n",
    "    def get_unwatched_movie_ids_from_user_id(self, user_id: int) -> List[int]:\n",
    "        watched_movie_ids = self.get_watched_movie_ids_from_user_id(user_id)\n",
    "        unwatched_movie_ids = list(\n",
    "            set(self.movies_df.index.tolist()) - set(watched_movie_ids)\n",
    "        )\n",
    "        return unwatched_movie_ids\n",
    "\n",
    "    def get_user_ids(self) -> List[int]:\n",
    "        return list(set(self.ratings_df.userId))\n",
    "\n",
    "    def get_top_k_popular_movie_ids(self, k: int) -> List[int]:\n",
    "        top_k_popular_movie_ids = (\n",
    "            self.ratings_df.groupby(\"movieId\")\n",
    "            .sum()\n",
    "            .sort_values(\"rating\", ascending=False)\n",
    "            .iloc[:k]\n",
    "            .index.tolist()\n",
    "        )\n",
    "        top_k_popular_movie_ids = [\n",
    "            int(movie_id) for movie_id in top_k_popular_movie_ids\n",
    "        ]\n",
    "        return top_k_popular_movie_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureStore:\n",
    "    def __init__(self, db: DB):\n",
    "        self.db = db\n",
    "\n",
    "    def get_features(self, user_id: int) -> Dict:\n",
    "        feature_dict = {\n",
    "            \"histories\": self.db.get_watched_movie_ids_from_user_id(user_id=user_id),\n",
    "            \"unwatched_movie_ids\": self.db.get_unwatched_movie_ids_from_user_id(\n",
    "                user_id=user_id\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        return feature_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self, model, feature_store: FeatureStore, db: DB):\n",
    "        self.model = model\n",
    "        self.feature_store = feature_store\n",
    "        self.db = db\n",
    "        self.k = 10  # n recommend movies to return\n",
    "\n",
    "    def recommend(self, user_id: int) -> Dict:\n",
    "        user_ids = self.db.get_user_ids()\n",
    "        if user_id not in user_ids:\n",
    "            top_k_movie_ids = self._get_popular_movie_ids()\n",
    "\n",
    "        else:\n",
    "            features = self.feature_store.get_features(user_id)\n",
    "\n",
    "            predictions = []\n",
    "            for unwatched_movie_id in features[\"unwatched_movie_ids\"]:\n",
    "                # TODO: change this both\n",
    "                inner_uid = user_id\n",
    "                inner_iid = unwatched_movie_id\n",
    "                prediction = self.model.predict(inner_uid, inner_iid)\n",
    "                predictions.append(prediction)\n",
    "\n",
    "            top_k_predictions = self._get_top_k(predictions, k=self.k)\n",
    "            top_k_movie_ids = [movie_id for movie_id, rating in top_k_predictions]\n",
    "\n",
    "        ouput_dict = {\"items\": [{\"id\": str(movie_id)} for movie_id in top_k_movie_ids]}\n",
    "\n",
    "        return ouput_dict\n",
    "\n",
    "    def recommend_with_metadata(self, user_id: int) -> Dict:\n",
    "        items_dict = self.recommend(user_id)\n",
    "        for i, item_data in enumerate(items_dict[\"items\"]):\n",
    "            movie_id = int(item_data[\"id\"])\n",
    "            metadata = self.db.get_metadata_from_movie_id(movie_id)\n",
    "            items_dict[\"items\"][i].update(metadata)\n",
    "\n",
    "        return items_dict\n",
    "\n",
    "    def _get_popular_movie_ids(self):\n",
    "        return self.db.get_top_k_popular_movie_ids(k=self.k)\n",
    "\n",
    "    def _get_top_k(self, predictions, k=10) -> List[Tuple[int, float]]:\n",
    "        topN = defaultdict(list)\n",
    "\n",
    "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "            topN[userID].append((movieID, estimatedRating))\n",
    "\n",
    "        for userID, ratings in topN.items():\n",
    "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            topN[userID] = ratings[:k]\n",
    "\n",
    "        return topN[userID]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(config.artifact_dir, \"algorithm_instance.pickle\")\n",
    "_, model = surprise.dump.load(model_path)\n",
    "db = DB(\n",
    "    links_csv_path=os.path.join(config.artifact_dir, \"cleaned_links.csv\"),\n",
    "    movies_csv_path=os.path.join(config.artifact_dir, \"cleaned_movies.csv\"),\n",
    "    ratings_csv_path=os.path.join(config.artifact_dir, \"cleaned_ratings.csv\"),\n",
    "    tags_csv_path=os.path.join(config.artifact_dir, \"cleaned_tags.csv\"),\n",
    ")\n",
    "feature_store = FeatureStore(db=db)\n",
    "recommender = Recommender(model=model, feature_store=feature_store, db=db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_output = recommender.recommend(-100)\n",
    "\n",
    "user_ids = db.get_user_ids()\n",
    "\n",
    "for user_id in user_ids:\n",
    "    print(\"user_id:\", user_id)\n",
    "    output = recommender.recommend(user_id)\n",
    "    assert output != popular_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
